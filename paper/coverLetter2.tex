\documentclass[10pt]{article}

\title{Reply to reviewers concerning submission AAA-D-19-00080R1: "Estimation of the perceived time of presence of sources in urban acoustic environments using deep learning techniques"}

\begin{document}

\maketitle

As a preamble, we would like to thank the editor and the reviewers for their comments and suggestions. Following these comments, we made several changes to the article, which are summarized here. The next section list our answers to each of the reviewerâ€™s comments, with references to the revised manuscript where appropriate.


\section{Answers to Reviewer III}

\begin{enumerate}

\item \emph{The revised version of this manuscript reads somewhat better than the original version. However, it still would benefit from further restructuring and the provision of further details. In the response letter, I find a lot of detailed information in the authors responses to the reviewers that are not implemented in the manuscript. If one think that some information is valuable to the reviewers, it is equality relevant to the readers of the published work. In general, all information provided to reviewers in the response letter must be implemented in the manuscript. For many journals, failure in doing so is reason enough for rejecting a manuscript from being published. Please, revise the manuscript accordingly.}

$\rightarrow$ All elements provided to the reviewers as part of the previous response letter are now presented in the manuscript. In particular, the choice of 45~s long extracts for the listening test and absence of controlled background noise in simulated sound scenes are now included in Section 2.1.

\item \emph{As I understand this manuscript, it contains three parts. Consequently, I propose that each part of the study should be allocated its own separate section.\\
Section 2 should report on the listening experiment, only. I propose that it is structured into subsections: 2.1 Participants, 2.2 Stimuli, 2.3 Data collection instrument, 2.4 Equipment, 2.5 Procedure and experimental design, and 2.6 Results. Add or remove subsections as appropriate.}

$\rightarrow$ Section 2 has been rewritten according to the following structure: 2.1 Stimuli, 2.2 Equipment, 2.3 Participants, 2.4 Procedure, 2.5 Results.

\item \emph{Section 3 should report on the machine learning study, including the corpus used and how it was generated. I still do not understand how the latter was done. How many different sounds for each source (traffic, voices, birds) were used to generate the scenes?}

$\rightarrow$ The machine learning corpus is now described in Section 3.1 (instead of Section 2.1). As is now emphasized, its generation procedure is the same as for the simulated sub-corpus of the listening test. However, the isolated samples database is different. Details of the isolated samples database have been added in Section 2.1 and 3.1  for the listening test corpus and the deep learning corpus respectively.

\item \emph{For the reader to be able to evaluate the validity of the study, it is necessary to know some more about how simScene works and how it utilized the information from the 74 recordings from the GRAFIC project to generate the scenes used.}

$\rightarrow$ The description of the generation procedure from distributions extracted from the GRAFIC project recordings using simScene has been extended in Section 2.1.

\item \emph{Section 4 should report on the application of the machine learning model to the prediction of pleasantness. The purpose and objective of this section must be clearly and explicitly communicated to the reader at the beginning of the section, providing a clear focus. Currently, the purpose of the section is not clear enough.}

$\rightarrow$ The introduction of Section 4 has been extended to better motivate the objective of this application.

\item \emph{Probably the presentation of the acoustic indices (now in Section 2.4) should be moved to Section 4, where they are used.}

$\rightarrow$ Acoustic indices are first used to identify a potential automatic annotation of the deep learning corpus in terms of perceived source presence. The presentation of these indices has thus been moved to Section 3.2.

\item \emph{In describing what the authors did, they must be precise and consistent in the terminology. For each phenomenon described, they must use exactly the same terms throughout the manuscript without any variation, so that the reader may understand what they are referring to. At present, there is too much variation in expressions, which is confusing. For example, on Row 261 the authors mention 75 selected extracts. What are those? Are they the same as the 75 simulated scenes mentioned previously?}

$\rightarrow$ The terminology used throughout the manuscript has been revised and is now more consistent.

\item \emph{For the listening experiment, I understand it as if the authors used 100 sound scenes, out of which 75 were simulated, 6 were recordings and 19 were replicated scenes from a previous project. What does it mean that the 19 scenes from a previous project were replicated? Where they simulations that match previously recorded scenes, or were they new recordings that are similar to previous recordings?}

$\rightarrow$ As is now more clearly described in Section 2.1, replicated sound scenes are generated using simScene, with scene composition (scenarios) constrained by annotations of the reference recordings. This differs from the 75 simulated sound scenes for which the scene composition is sampled from gaussian distributions.

\item \emph{On Row 247, the authors mention that 200 scenes were generated. Does it mean that the 75 simulated scenes used were selected among the 200?}

$\rightarrow$ As the generation procedure for simulated scenes includes random sampling from distributions, simScene may output similar sound scenes. To avoid this phenomenon in the listening test corpus, 200 scenes are first generated, among which 75 scenes are selected to maximize content diversity.

\item \emph{On Rows 256-260: The authors write that "Ideally, sound scenes should cover the resulting 3-dimensional space in a homogeneous way. To do so, the 75 scenes that maximize the minimum pairwise distance in the 3-dimensional space are selected."\\
I am not sure that I understand what 3D space the authors are referring to. Do they mean the 3D space of Traffic, Voices and Birds presented in Figure 1? If so, then please spell this out explicitly in the text, including what this 3D space represents and how it was created. Please also explain how to "maximize the minimum pairwise distance."\\
I find it very hard to understand Figure 1 from the limited information provided. It must be improved (or removed).}

$\rightarrow$ The selection procedure description has been simplified and Figure 1 has been removed to enhance the reader's comprehension, as the considered indicator for the selection of the 75 simulated scenes was not presented until Section 2.4 (now 3.2).

\item \emph{On Row 285, I wonder what it means that the authors "normalized" the sounds. Does it mean that the authors calibrated the sounds to the authentic sound levels?}

$\rightarrow$ The sound scenes are scaled so that they are heard at the desired sound level (as measured in the case of recorded and replicated scenes) when using the specific configuration (headphones, sound card) presented in Section 2.2. The term "normalized" has been replaced with "scaled" to avoid confusion.

\item \emph{On Rows 290-291, the authors write that the participants used 8 criteria to evaluate the sounds. I suppose that it means that they used 8 attributes. It also seems as if the authors used 11-point bipolar scales, delimited by opposite terms. Then the term 'Likert scale' used on Row 370 is incorrect. A Likert scale is a 5-point category scale asking to what extent a person agrees or disagrees with a statement. As far as I can tell, the authors did not use any Likert scales.}

$\rightarrow$ The term "Likert scale" has been removed throughout the manuscript.

\item \emph{Rows 329, 345, 352 and 414: Replace 'subjects,' with 'participants.'}

$\rightarrow$ All mentions of "subjects" are now replaced with "participants".

\item \emph{I do not understand the information provided in the paragraph about the sound level calibration on Rows 334-348. Particularly, I do not understand the rationale for the calibration procedure. It must be explained in some more detail. Perhaps a conceptual diagram showing how the different equipment were connected would be helpful? The reader should be able to replicate what was done based on the information provided in the manuscript.}

$\rightarrow$ The steps undertaken during the calibration procedure are now detailed in Section 2.2. From this procedure, a simple (linear) relation is obtained between the voltage at the output of the sound card and the sound level produced by the headphones. Sound scenes can be scaled using this information so that they are played at the desired sound level using the specific headphones and sound card configuration.

\item \emph{On Rows 401-403 it seems as if the 6 recorded and 19 replicated scenes (n=25) all were recordings. Is that so?}

$\rightarrow$ The 19 replicated scenes are generated by simScene, and thus are not recordings. This part has been rewritten to avoid any confusion in this regard.

\item \emph{Figures 2 and 3: Please observe that these two figures present Principal Components Loadings for the five attribute scales. Because the scales are bipolar, it is confusing to see lines extending in two directions. There should only be five vectors extending from the origin of the space to the points in the 2D space that represent the coordinates of the loadings on the two Principal Components. Moreover, I am not sure that it is necessary to include the ellipses, short arrows and datapoints in these figures. I just find it messy.}

$\rightarrow$ Both figures displaying the principal components analyses have been modified so that loadings are in one direction only. Furthermore, the ellipses and arrows have been removed along with the corresponding text. They are available as supplementary material on the companion website.

\item \emph{How were the PCA conducted and with what statistical package? [...] What statistical package was used to calculate the correlation coefficients? [...] What statistical package was used for conduction the regression analyses?}

$\rightarrow$ All statistical analyses are conducted using Matlab. This is emphasized in the introduction as well as in the beginning of Section 2.5. The code is also made available for further information about the specific functions used.

\item \emph{Equations 2 and 3 must be better explained, and presented separately. Please use plain language, to explain what the equations mean.}

$\rightarrow$ The description of both equations has been extended to enhance the reader's comprehension.

\item \emph{Table 2: I expect to see * p<0.05 and ** p<0.001 as foot notes below the table and not in the caption.}

$\rightarrow$ Significance thresholds have been moved to table footnotes where applicable.

\item \emph{Are they 1- or 2-tailed probabilities?}

$\rightarrow$ The Matlab \textit{corrcoef} function was used to compute all correlation coefficients. The corresponding significance test is two-tailed. This is now stated in Section 3.2 and 4.1, where correlation coefficients are presented.

\item \emph{The authors must also explain all abbreviations in the table. It must be possible to read tables and figures independently of the text body. Please, include all correlation coefficients in the table, also those that are not statistically significant.}

$\rightarrow$ Abbreviations of perceptual attributes have been added to the respective table captions. Non-significant correlations have also been added to Table 2.

\item \emph{In Section 4, I miss the relevant F- and t- statistics for the regression models. For each model, one must report the overall F-statistics and the t-statistics for each factor included in the models. This is typically presented in the text body.}

$\rightarrow$ F- and t- statistics have been added to the text following equations 5 and 6 on the baseline models of pleasantness.

\item \emph{For each model, the authors must also explain what data was used (which corpus).}

$\rightarrow$ Baseline models of pleasantness are computed on the listening test corpus, as the considered perceptual attributes are available on this corpus only. The baseline model from acoustic indices is computed on a subset of 92 sound scenes as the computation of time of presence estimations requires separated source contributions, which are not available in the 6 recorded scenes. These elements are now more clearly described in Section 4.1.

\end{enumerate}



\bibliographystyle{unsrt}
\bibliography{refs}

\end{document}
